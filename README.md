# Базовая настройка

## Запуск minikube

[Инструкция по установке](https://minikube.sigs.k8s.io/docs/start/)

```bash
minikube start
```

## Добавление токена авторизации GitHub

[Получение токена](https://github.com/settings/tokens/new)

```bash
kubectl create secret docker-registry ghcr --docker-server=https://ghcr.io --docker-username=<github_username> --docker-password=<github_token> -n default
```

## Установка API GW kusk

[Install Kusk CLI](https://docs.kusk.io/getting-started/install-kusk-cli)

```bash
kusk cluster install
```

## Смена адреса образа в helm chart

После того как вы сделали форк репозитория и у вас в репозитории отработал GitHub Action. Вам нужно получить адрес образа <https://github.com/><github_username>/architecture-sprint-3/pkgs/container/architecture-sprint-3

Он выглядит таким образом
```ghcr.io/<github_username>/architecture-sprint-3:latest```

Замените адрес образа в файле `helm/smart-home-monolith/values.yaml` на полученный файл:

```yaml
image:
  repository: ghcr.io/<github_username>/architecture-sprint-3
  tag: latest
```

## Настройка terraform

[Установите Terraform](https://yandex.cloud/ru/docs/tutorials/infrastructure-management/terraform-quickstart#install-terraform)

Создайте файл ~/.terraformrc

```hcl
provider_installation {
  network_mirror {
    url = "https://terraform-mirror.yandexcloud.net/"
    include = ["registry.terraform.io/*/*"]
  }
  direct {
    exclude = ["registry.terraform.io/*/*"]
  }
}
```

## Применяем terraform конфигурацию

```bash
cd terraform
terraform init
terraform apply
```

## Настройка API GW

```bash
kusk deploy -i api.yaml
```

## Проверяем работоспособность

```bash
kubectl port-forward svc/kusk-gateway-envoy-fleet -n kusk-system 8080:80
curl localhost:8080/hello
```

## Delete minikube

```bash
minikube delete
```


## Задание 1

### Общий анализ приложения As-Is

Насколько я понимаю Java и не имею никакого представления о Spring - в этом
приложении слишком мало кода. В нем скорее слишком много недостающего функционала,
чем чего-то полезного для бизнеса.

Например, хоть и объявлены структуры данных для температурных сенсоров, в приложении
начисто отсутствуют методы коммуникации чтобы управлять этими сущностями.
Так же вызывает вопрос и решение об отсутствии интерфейса для наполнения таблицы
heating_systems данными. А без данных в этой таблице все попытки что-то изменить
будут заканчиваться печально. Видимо этой деятельностью занимаются люди в офисе
с прямым доступом к БД.

Если принять, что система отопления имеет внутренний цикл около минуты, то при
100 подключенных устройствах к нашему монолиту в среднем в синхронном режиме 
надо иметь время отклика монолита около 0.6 секунды. Это вполне приемлимая
скорость работы и тут вряд ли какой-нибудь из компонентов станет узким местом.

Масштабировать такой монолит можно, но в ограниченных объемах. Так как все
коммуникации в приложении stateless, то вполне возможно запустить несколько
экземпляров приложения и вместо ```/src/main/resources/application.yml```
указывать порт через параметр JVM как ```jvm -Dserver.port=8090```. Тогда на одном
хосте при наличии ЦПУ и ОЗУ можно обрабатывать в два раза больше запросов при
двух экземплярах приложения. Балансировку между ними можно запросто делать с
помощью HAProxy. При достаточном количесстве экземрляров можно сгладить достаточно
большое время на запуск и перезапуск экземпляра JVM. Так же это позволит использовать
и методы "канарейки" или "green-blue" для постепенного обновления приложения.

Масштабировать на уровне БД вряд ли придется так как Primary Key constraint
уже есть у каждой из таблиц. Пока там не будет миллионов записей большого смысла в их
партиционировании при работе только через PK индекс не будет. Размер записей
в этих таблицах тоже мал, поэтому и файлы данных и индексов будут сравнительно
небольшими. Тут PostgreSQL по своему обычаю будет полагаться и выигрывать от кэша 
ОС, которая будет с удовольствием хранить их в свем кэше.

Для повышения надежности уровня БД необходимо иметь 2 копии БД (primary и standby).
Это автоматически позволяет добавть возможность разделения пишущего и читающего
трафика в БД с помощью того же HAProxy. При большом количестве устройств, скорее
всего пишущая нагрузка будет превышать читающую и тут PostgreSQL в конфигурации
физической реплики станет узким местом. Далее это можно будет преодолеть с
помощью переключение на логическую репликацию в master-master конфигурации. Тут,
конечно же, всплывут проблемы обновления данных на одном сервере БД и дальнейшая
попытка прочитать эти же данные, но уже с другого сервера до окончания репликации
между ними. В данном приложении эту проблему можно решить через кэш.

И "последним вздохом имератора" (нашего монолита) может стать попытка ускорить
слой БД за счет добавления Redis. Тогда запросы типа GET ```/{id}``` и
```/{id}/current-temperature``` можно обслуживать быстрее, а информацию в Redis
обновлять во время выполнения соответствующих PUT и POST запросов.

Кстати, что интересно - это то, что система в принципе не обрабатывает DELETE
запросы. Это означает, что ошибочно введенные данные (например, новые устройства)
не имеют возможности быть удалены. Но, видимо, этим тоже занимаются люди в офисе
с прямым доступом к БД.

В итоге можно сказать, что у данного приложения есть перспективы по масштабируемости
для обслуживания более чем текущие 100 устройств раз в 10. Но все же, если в
планах заняться обслуживанием 100 * 200 * 5 = 100'000 устройств, то тут монолиту
будет тяжело. Ведь при тех же ежеминутных обновлениях это уже 0.0006 сек для
синхронной обработки данных в один канал.

### Домены и границы контекстов

Я бы предложил делить монолит на домены по типу устройств. Закон Конвея нам тут
не мешает, так как компания достаточно маленькая. А вот задав общий метод как
"один тип устройств = один микросервис" мы получаем гибкость как во внедрении
нового типа устройств, когда не надо будет открыватели ворот управлять теми же
интерфейсами, что и лампочки в доме. Так и снижение риска при таком внедрении,
когда новый функционал никак не влияет на инфраструктуру остальных доменов.

У каждого из таких доменов будут четкие контексты, которые присущи именно
конкретному типу устройств. Например, не только "Включить", "Выключить" и "Снять
показания", но и "Открыть", "Закрыть" и т.п.

### Диаграмма

Диаграмма монолита представлена в файле [task_1_monolith](./diagrams/task_1_monolith.puml)

## Задание 2
## Задание 3
